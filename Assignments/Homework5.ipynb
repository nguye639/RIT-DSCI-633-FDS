{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Load data in, keras already has it train-test split\n",
    "(trainX,trainY), (testX, testY) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "print(trainX.shape,trainY.shape)\n",
    "print(testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainX[0])\n",
    "print(trainY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and scale the features\n",
    "trainX = trainX.reshape((trainX.shape[0], 28*28))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainX)\n",
    "trainX = scaler.transform(trainX)\n",
    "\n",
    "testX = testX.reshape((testX.shape[0], 28*28))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(testX)\n",
    "testX = scaler.transform(testX)\n",
    "\n",
    "trainY =  keras.utils.to_categorical(trainY, 10)\n",
    "testY =  keras.utils.to_categorical(testY, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 11:28:30.339000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-13 11:28:30.339000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-13 11:28:30.630442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-13 11:28:30.630442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: nan - accuracy: 0.1698\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: nan - accuracy: 0.1698\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: nan - accuracy: 0.0312Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: nan - accuracy: 0.1875Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 19s - loss: nan - accuracy: 0.0625\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: nan - accuracy: 0.1562Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 6s - loss: nan - accuracy: 0.0938Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: nan - accuracy: 0.1875Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: nan - accuracy: 0.0938Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: nan - accuracy: 0.1875Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: nan - accuracy: 0.1562Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy: 0.098 - ETA: 0s - loss: n\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0ee81f640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0ee81f640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model\n",
    "fct = 'relu'\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(trainX, trainY, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3141 - accuracy: 0.9132 - val_loss: 0.1829 - val_accuracy: 0.9459\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3141 - accuracy: 0.9132 - val_loss: 0.1829 - val_accuracy: 0.9459\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 15s - loss: 0.1702 - accuracy: 0.9688Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1327 - accuracy: 0.9612 - val_loss: 0.1327 - val_accuracy: 0.9613\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1327 - accuracy: 0.9612 - val_loss: 0.1327 - val_accuracy: 0.9613\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.0676 - accuracy: 0.9688Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9754 - val_loss: 0.1125 - val_accuracy: 0.9671\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9754 - val_loss: 0.1125 - val_accuracy: 0.9671\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.1137 - accuracy: 0.9688Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.1056 - val_accuracy: 0.9697TA: 0s - loss: 0.0563 - accuracy:1703/1875 [=====================\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.1056 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 17s - loss: 0.0337 - accuracy: 1.0000Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0378 - accuracy: 0.9907 - val_loss: 0.1007 - val_accuracy: 0.9711\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0378 - accuracy: 0.9907 - val_loss: 0.1007 - val_accuracy: 0.9711\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.0566 - accuracy: 0.9688Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.0992 - val_accuracy: 0.9711\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.0992 - val_accuracy: 0.9711\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.0045 - accuracy: 1.0000Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.0964 - val_accuracy: 0.9739\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.0964 - val_accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.0040 - accuracy: 1.0000Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.0973 - val_accuracy: 0.9736\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.0973 - val_accuracy: 0.9736\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 8.4536e-04 - accuracy: 1.0000Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1003 - val_accuracy: 0.9740\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1003 - val_accuracy: 0.9740\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.0074 - accuracy: 1.0000Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0991 - val_accuracy: 0.9744\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0991 - val_accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6721 - accuracy: 0.7866\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6721 - accuracy: 0.7866\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5155 - accuracy: 0.9309\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5155 - accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.4468 - accuracy: 0.9062Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3328 - accuracy: 0.9406\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3328 - accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.2669 - accuracy: 0.9375Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2745 - accuracy: 0.94700s - loss: 0.2751 - accuracy: 0.9468 - ETA: 0s - l\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2745 - accuracy: 0.9470\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.2479 - accuracy: 0.9375Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2412 - accuracy: 0.9519\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2412 - accuracy: 0.9519\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.1137 - accuracy: 0.9688Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2189 - accuracy: 0.9551\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2189 - accuracy: 0.9551\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.0593 - accuracy: 1.0000Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2037 - accuracy: 0.9579\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2037 - accuracy: 0.9579\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 0.2444 - accuracy: 0.9375Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1923 - accuracy: 0.9600\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1923 - accuracy: 0.9600\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.0401 - accuracy: 1.0000Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1841 - accuracy: 0.9617\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1841 - accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 18s - loss: 0.0461 - accuracy: 1.0000Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1771 - accuracy: 0.9634\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1771 - accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0d7cea640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0d7cea640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model\n",
    "fct = 'softmax'\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(trainX, trainY, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(fct,lr):\n",
    "#Build model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "    model.add(layers.Dense(128, activation=fct))\n",
    "    model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "    #Make exponential learning rate\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        lr,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9,\n",
    "        staircase=False)\n",
    "\n",
    "    #Define optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10, verbose = 0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 21.3180 - accuracy: 0.0992 - val_loss: 17.6868 - val_accuracy: 0.1135\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 21.3180 - accuracy: 0.0992 - val_loss: 17.6868 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 20s - loss: 15.8970 - accuracy: 0.0625Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 15.9132 - accuracy: 0.1017 - val_loss: 12.0165 - val_accuracy: 0.1009\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 15.9132 - accuracy: 0.1017 - val_loss: 12.0165 - val_accuracy: 0.1009\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 44s - loss: 12.5192 - accuracy: 0.0000e+00Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 11.6269 - accuracy: 0.0989 - val_loss: 9.0179 - val_accuracy: 0.0974\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 11.6269 - accuracy: 0.0989 - val_loss: 9.0179 - val_accuracy: 0.0974\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 16s - loss: 7.5527 - accuracy: 0.1875Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 8.2857 - accuracy: 0.0982 - val_loss: 4.0304 - val_accuracy: 0.1135\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 8.2857 - accuracy: 0.0982 - val_loss: 4.0304 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 3.7810 - accuracy: 0.1250Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.1125 - accuracy: 0.0996 - val_loss: 5.4968 - val_accuracy: 0.1009\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.1125 - accuracy: 0.0996 - val_loss: 5.4968 - val_accuracy: 0.1009\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 14s - loss: 6.1848 - accuracy: 0.0938Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 4.5933 - accuracy: 0.0978 - val_loss: 4.3089 - val_accuracy: 0.1010\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 4.5933 - accuracy: 0.0978 - val_loss: 4.3089 - val_accuracy: 0.1010\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 4.4897 - accuracy: 0.0625Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 4.0071 - accuracy: 0.1008 - val_loss: 3.0155 - val_accuracy: 0.1135\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 4.0071 - accuracy: 0.1008 - val_loss: 3.0155 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 2.8999 - accuracy: 0.1562Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.3163 - accuracy: 0.1010 - val_loss: 3.4930 - val_accuracy: 0.0974\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.3163 - accuracy: 0.1010 - val_loss: 3.4930 - val_accuracy: 0.0974\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 3.4327 - accuracy: 0.1875Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 3.1054 - accuracy: 0.1004 - val_loss: 3.1845 - val_accuracy: 0.0980\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 3.1054 - accuracy: 0.1004 - val_loss: 3.1845 - val_accuracy: 0.0980\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 22s - loss: 2.8522 - accuracy: 0.1562Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.9738 - accuracy: 0.1008 - val_loss: 2.8600 - val_accuracy: 0.0980\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.9738 - accuracy: 0.1008 - val_loss: 2.8600 - val_accuracy: 0.0980\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 1.8940 - accuracy: 0.3298 - val_loss: 1.6707 - val_accuracy: 0.3766\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 1.8940 - accuracy: 0.3298 - val_loss: 1.6707 - val_accuracy: 0.3766\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 2.0650 - accuracy: 0.2812Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 1.7036 - accuracy: 0.3616 - val_loss: 1.7280 - val_accuracy: 0.3472\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 1.7036 - accuracy: 0.3616 - val_loss: 1.7280 - val_accuracy: 0.3472\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 19s - loss: 1.6061 - accuracy: 0.4375Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.6101 - accuracy: 0.3700 - val_loss: 1.4515 - val_accuracy: 0.3730\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.6101 - accuracy: 0.3700 - val_loss: 1.4515 - val_accuracy: 0.3730\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 1.6420 - accuracy: 0.3750Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.5523 - accuracy: 0.3720 - val_loss: 1.6507 - val_accuracy: 0.3723\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.5523 - accuracy: 0.3720 - val_loss: 1.6507 - val_accuracy: 0.3723\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 19s - loss: 1.6617 - accuracy: 0.2812Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5155 - accuracy: 0.3751 - val_loss: 1.3916 - val_accuracy: 0.3844\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5155 - accuracy: 0.3751 - val_loss: 1.3916 - val_accuracy: 0.3844\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 1.3139 - accuracy: 0.3750Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4561 - accuracy: 0.3780 - val_loss: 1.3884 - val_accuracy: 0.3883\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4561 - accuracy: 0.3780 - val_loss: 1.3884 - val_accuracy: 0.3883\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 33s - loss: 1.3044 - accuracy: 0.3125Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4181 - accuracy: 0.3830 - val_loss: 1.4560 - val_accuracy: 0.3863\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4181 - accuracy: 0.3830 - val_loss: 1.4560 - val_accuracy: 0.3863\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 1.4673 - accuracy: 0.3125Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.3942 - accuracy: 0.3844 - val_loss: 1.3692 - val_accuracy: 0.3787\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.3942 - accuracy: 0.3844 - val_loss: 1.3692 - val_accuracy: 0.3787\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 1.7372 - accuracy: 0.3438Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3652 - accuracy: 0.3855 - val_loss: 1.3895 - val_accuracy: 0.3795\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3652 - accuracy: 0.3855 - val_loss: 1.3895 - val_accuracy: 0.3795\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 1.2566 - accuracy: 0.4375Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3386 - accuracy: 0.3836 - val_loss: 1.3330 - val_accuracy: 0.3846\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3386 - accuracy: 0.3836 - val_loss: 1.3330 - val_accuracy: 0.3846\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2575 - accuracy: 0.9217 - val_loss: 0.1726 - val_accuracy: 0.9488\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2575 - accuracy: 0.9217 - val_loss: 0.1726 - val_accuracy: 0.9488\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.2172 - accuracy: 0.9688Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1512 - accuracy: 0.9531 - val_loss: 0.1542 - val_accuracy: 0.9540\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1512 - accuracy: 0.9531 - val_loss: 0.1542 - val_accuracy: 0.9540\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.0629 - accuracy: 1.0000Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1147 - accuracy: 0.9642 - val_loss: 0.1383 - val_accuracy: 0.9595\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1147 - accuracy: 0.9642 - val_loss: 0.1383 - val_accuracy: 0.9595\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.0819 - accuracy: 0.9688Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0832 - accuracy: 0.9736 - val_loss: 0.1357 - val_accuracy: 0.9592\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0832 - accuracy: 0.9736 - val_loss: 0.1357 - val_accuracy: 0.9592\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.0197 - accuracy: 1.0000Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.1285 - val_accuracy: 0.9636\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.1285 - val_accuracy: 0.9636\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 49s - loss: 0.0368 - accuracy: 0.9688Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.1195 - val_accuracy: 0.9669\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.1195 - val_accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.0028 - accuracy: 1.0000Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.1244 - val_accuracy: 0.9658\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.1244 - val_accuracy: 0.9658\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 0.0093 - accuracy: 1.0000Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1249 - val_accuracy: 0.9674\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1249 - val_accuracy: 0.9674\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 20s - loss: 0.0099 - accuracy: 1.0000Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.1243 - val_accuracy: 0.9694\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.1243 - val_accuracy: 0.9694\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 6.9931e-04 - accuracy: 1.0000Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1275 - val_accuracy: 0.9689\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1275 - val_accuracy: 0.9689\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.3084 - accuracy: 0.9152 - val_loss: 0.1793 - val_accuracy: 0.9467\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.3084 - accuracy: 0.9152 - val_loss: 0.1793 - val_accuracy: 0.9467\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.1651 - accuracy: 0.9062Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1337 - accuracy: 0.9606 - val_loss: 0.1363 - val_accuracy: 0.9598\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1337 - accuracy: 0.9606 - val_loss: 0.1363 - val_accuracy: 0.9598\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.0181 - accuracy: 1.0000Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0855 - accuracy: 0.9745 - val_loss: 0.1164 - val_accuracy: 0.9671\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0855 - accuracy: 0.9745 - val_loss: 0.1164 - val_accuracy: 0.9671\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 58s - loss: 0.0358 - accuracy: 1.0000Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0567 - accuracy: 0.9849 - val_loss: 0.1099 - val_accuracy: 0.9698\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0567 - accuracy: 0.9849 - val_loss: 0.1099 - val_accuracy: 0.9698\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.0289 - accuracy: 0.9688Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0383 - accuracy: 0.9901 - val_loss: 0.1039 - val_accuracy: 0.9716\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0383 - accuracy: 0.9901 - val_loss: 0.1039 - val_accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 19s - loss: 0.0140 - accuracy: 1.0000Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0264 - accuracy: 0.9941 - val_loss: 0.1062 - val_accuracy: 0.9702\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0264 - accuracy: 0.9941 - val_loss: 0.1062 - val_accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.0106 - accuracy: 1.0000Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.1039 - val_accuracy: 0.9712\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.1039 - val_accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 24s - loss: 0.0026 - accuracy: 1.0000Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1058 - val_accuracy: 0.9713\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1058 - val_accuracy: 0.9713\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 15s - loss: 0.0088 - accuracy: 1.0000Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.1074 - val_accuracy: 0.9714\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.1074 - val_accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 37s - loss: 0.0024 - accuracy: 1.0000Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.1094 - val_accuracy: 0.9711\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.1094 - val_accuracy: 0.9711\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8725 - accuracy: 0.8200 - val_loss: 0.4143 - val_accuracy: 0.8993\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8725 - accuracy: 0.8200 - val_loss: 0.4143 - val_accuracy: 0.8993\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 6s - loss: 0.3175 - accuracy: 0.9375Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3495 - accuracy: 0.9092 - val_loss: 0.3015 - val_accuracy: 0.9160\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3495 - accuracy: 0.9092 - val_loss: 0.3015 - val_accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.4000 - accuracy: 0.9062Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2794 - accuracy: 0.9224 - val_loss: 0.2637 - val_accuracy: 0.9256\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2794 - accuracy: 0.9224 - val_loss: 0.2637 - val_accuracy: 0.9256\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.1632 - accuracy: 0.9688Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2482 - accuracy: 0.9296 - val_loss: 0.2437 - val_accuracy: 0.9293\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2482 - accuracy: 0.9296 - val_loss: 0.2437 - val_accuracy: 0.9293\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.3046 - accuracy: 0.8438Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2294 - accuracy: 0.9347 - val_loss: 0.2311 - val_accuracy: 0.9331\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2294 - accuracy: 0.9347 - val_loss: 0.2311 - val_accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 6s - loss: 0.1272 - accuracy: 0.9688Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2165 - accuracy: 0.9384 - val_loss: 0.2231 - val_accuracy: 0.9356\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2165 - accuracy: 0.9384 - val_loss: 0.2231 - val_accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.0617 - accuracy: 1.0000Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2072 - accuracy: 0.9406 - val_loss: 0.2165 - val_accuracy: 0.9374\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2072 - accuracy: 0.9406 - val_loss: 0.2165 - val_accuracy: 0.9374\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 14s - loss: 0.1289 - accuracy: 0.9688Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2000 - accuracy: 0.9428 - val_loss: 0.2119 - val_accuracy: 0.9384\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2000 - accuracy: 0.9428 - val_loss: 0.2119 - val_accuracy: 0.9384\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.2979 - accuracy: 0.9062Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1946 - accuracy: 0.9444 - val_loss: 0.2083 - val_accuracy: 0.9393\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1946 - accuracy: 0.9444 - val_loss: 0.2083 - val_accuracy: 0.9393\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.1789 - accuracy: 0.9688Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1902 - accuracy: 0.9454 - val_loss: 0.2054 - val_accuracy: 0.9399\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1902 - accuracy: 0.9454 - val_loss: 0.2054 - val_accuracy: 0.9399\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.0165 - accuracy: 0.4900 - val_loss: 1.7093 - val_accuracy: 0.7300\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.0165 - accuracy: 0.4900 - val_loss: 1.7093 - val_accuracy: 0.7300\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 1.8465 - accuracy: 0.5625Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5013 - accuracy: 0.7586 - val_loss: 1.3147 - val_accuracy: 0.7929\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5013 - accuracy: 0.7586 - val_loss: 1.3147 - val_accuracy: 0.7929\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 1.3574 - accuracy: 0.7500Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1934 - accuracy: 0.8023 - val_loss: 1.0784 - val_accuracy: 0.8238\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1934 - accuracy: 0.8023 - val_loss: 1.0784 - val_accuracy: 0.8238\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 1.1164 - accuracy: 0.8750Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0059 - accuracy: 0.8264 - val_loss: 0.9307 - val_accuracy: 0.8409\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0059 - accuracy: 0.8264 - val_loss: 0.9307 - val_accuracy: 0.8409\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.9718 - accuracy: 0.9062Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8858 - accuracy: 0.8404 - val_loss: 0.8333 - val_accuracy: 0.8525\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8858 - accuracy: 0.8404 - val_loss: 0.8333 - val_accuracy: 0.8525\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.7052 - accuracy: 0.9375Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8047 - accuracy: 0.8511 - val_loss: 0.7661 - val_accuracy: 0.8601\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8047 - accuracy: 0.8511 - val_loss: 0.7661 - val_accuracy: 0.8601\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.7547 - accuracy: 0.8750Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7481 - accuracy: 0.8582 - val_loss: 0.7185 - val_accuracy: 0.8659\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7481 - accuracy: 0.8582 - val_loss: 0.7185 - val_accuracy: 0.8659\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.5950 - accuracy: 0.9688Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7072 - accuracy: 0.8628 - val_loss: 0.6838 - val_accuracy: 0.8701\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7072 - accuracy: 0.8628 - val_loss: 0.6838 - val_accuracy: 0.8701\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.6966 - accuracy: 0.9062Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6771 - accuracy: 0.8662 - val_loss: 0.6578 - val_accuracy: 0.8730\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6771 - accuracy: 0.8662 - val_loss: 0.6578 - val_accuracy: 0.8730\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 42s - loss: 0.6933 - accuracy: 0.8125Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6544 - accuracy: 0.8684 - val_loss: 0.6381 - val_accuracy: 0.8749\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6544 - accuracy: 0.8684 - val_loss: 0.6381 - val_accuracy: 0.8749\n"
     ]
    }
   ],
   "source": [
    "#Sigmoid function was the best in the previous models, so that will be used here\n",
    "lr = [1.0,.1,.01,.001,.0001,.00001]\n",
    "loss = []\n",
    "for i in range(0,len(lr)):\n",
    "    history = model('sigmoid',lr[i])\n",
    "    loss.append(history.history['loss'][-1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shoots back up at a learning rate of .00001\n",
      "Loss shoots back up at a learning rate of .00001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr,loss)\n",
    "plt.xlim(1,-.1)\n",
    "plt.title(\"Learning Rate v.s. Loss\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\");\n",
    "print(\"Loss shoots back up at a learning rate of .00001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8865 - accuracy: 0.8137 - val_loss: 0.4164 - val_accuracy: 0.9042\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8865 - accuracy: 0.8137 - val_loss: 0.4164 - val_accuracy: 0.9042\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.4329 - accuracy: 0.9062Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3504 - accuracy: 0.9095 - val_loss: 0.3026 - val_accuracy: 0.9175\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3504 - accuracy: 0.9095 - val_loss: 0.3026 - val_accuracy: 0.9175\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.1849 - accuracy: 0.9688Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2799 - accuracy: 0.9225 - val_loss: 0.2648 - val_accuracy: 0.9250\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2799 - accuracy: 0.9225 - val_loss: 0.2648 - val_accuracy: 0.9250\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.1024 - accuracy: 1.0000Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2491 - accuracy: 0.9297 - val_loss: 0.2444 - val_accuracy: 0.9302\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2491 - accuracy: 0.9297 - val_loss: 0.2444 - val_accuracy: 0.9302\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.3157 - accuracy: 0.8750Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2304 - accuracy: 0.9347 - val_loss: 0.2328 - val_accuracy: 0.9325\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2304 - accuracy: 0.9347 - val_loss: 0.2328 - val_accuracy: 0.9325\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.1692 - accuracy: 0.9688Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2177 - accuracy: 0.9379 - val_loss: 0.2241 - val_accuracy: 0.9349\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2177 - accuracy: 0.9379 - val_loss: 0.2241 - val_accuracy: 0.9349\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 33s - loss: 0.3533 - accuracy: 0.8750Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2084 - accuracy: 0.9406 - val_loss: 0.2181 - val_accuracy: 0.9372\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2084 - accuracy: 0.9406 - val_loss: 0.2181 - val_accuracy: 0.9372\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 0.1193 - accuracy: 0.9688Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2013 - accuracy: 0.9426 - val_loss: 0.2134 - val_accuracy: 0.9384\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2013 - accuracy: 0.9426 - val_loss: 0.2134 - val_accuracy: 0.9384\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.3479 - accuracy: 0.8750Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1959 - accuracy: 0.9444 - val_loss: 0.2099 - val_accuracy: 0.9391\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1959 - accuracy: 0.9444 - val_loss: 0.2099 - val_accuracy: 0.9391\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.1739 - accuracy: 0.9688Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1917 - accuracy: 0.9449 - val_loss: 0.2067 - val_accuracy: 0.9405\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1917 - accuracy: 0.9449 - val_loss: 0.2067 - val_accuracy: 0.9405\n"
     ]
    }
   ],
   "source": [
    "Loss =[]\n",
    "#Adam \n",
    "#Build model\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10)\n",
    "Loss.append(history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3444 - accuracy: 0.1130 - val_loss: 2.3035 - val_accuracy: 0.1171\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3444 - accuracy: 0.1130 - val_loss: 2.3035 - val_accuracy: 0.1171\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 2.2133 - accuracy: 0.1250Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2886 - accuracy: 0.1278 - val_loss: 2.2750 - val_accuracy: 0.1384\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2886 - accuracy: 0.1278 - val_loss: 2.2750 - val_accuracy: 0.1384\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 2.2204 - accuracy: 0.3125Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2690 - accuracy: 0.1532 - val_loss: 2.2615 - val_accuracy: 0.1635: 0s - loss: 2.2693 - ac\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2690 - accuracy: 0.1532 - val_loss: 2.2615 - val_accuracy: 0.1635\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 5s - loss: 2.3224 - accuracy: 0.0938Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2583 - accuracy: 0.1770 - val_loss: 2.2531 - val_accuracy: 0.1851\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2583 - accuracy: 0.1770 - val_loss: 2.2531 - val_accuracy: 0.1851\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 2.2699 - accuracy: 0.1562Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2512 - accuracy: 0.1968 - val_loss: 2.2470 - val_accuracy: 0.2052\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2512 - accuracy: 0.1968 - val_loss: 2.2470 - val_accuracy: 0.2052\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 2.2396 - accuracy: 0.2812Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2459 - accuracy: 0.2152 - val_loss: 2.2423 - val_accuracy: 0.2197\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2459 - accuracy: 0.2152 - val_loss: 2.2423 - val_accuracy: 0.2197\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 2.2221 - accuracy: 0.2812Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2418 - accuracy: 0.2304 - val_loss: 2.2386 - val_accuracy: 0.2319\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2418 - accuracy: 0.2304 - val_loss: 2.2386 - val_accuracy: 0.2319\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 2.2844 - accuracy: 0.1250Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2385 - accuracy: 0.2420 - val_loss: 2.2356 - val_accuracy: 0.2414\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2385 - accuracy: 0.2420 - val_loss: 2.2356 - val_accuracy: 0.2414\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 2.2518 - accuracy: 0.2500Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2358 - accuracy: 0.2514 - val_loss: 2.2332 - val_accuracy: 0.2519\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2358 - accuracy: 0.2514 - val_loss: 2.2332 - val_accuracy: 0.2519\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 2.2119 - accuracy: 0.3750Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2337 - accuracy: 0.2580 - val_loss: 2.2312 - val_accuracy: 0.2593\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2337 - accuracy: 0.2580 - val_loss: 2.2312 - val_accuracy: 0.2593\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "#SGD\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10)\n",
    "Loss.append(history.history['loss'][-1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8152 - accuracy: 0.8271 - val_loss: 0.3896 - val_accuracy: 0.8995\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8152 - accuracy: 0.8271 - val_loss: 0.3896 - val_accuracy: 0.8995\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 14s - loss: 0.3628 - accuracy: 0.9375Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3379 - accuracy: 0.9087 - val_loss: 0.3006 - val_accuracy: 0.9155\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3379 - accuracy: 0.9087 - val_loss: 0.3006 - val_accuracy: 0.9155\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 15s - loss: 0.3387 - accuracy: 0.9062Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2830 - accuracy: 0.9189 - val_loss: 0.2697 - val_accuracy: 0.9231\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2830 - accuracy: 0.9189 - val_loss: 0.2697 - val_accuracy: 0.9231\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.1819 - accuracy: 0.9688Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2581 - accuracy: 0.9244 - val_loss: 0.2531 - val_accuracy: 0.9275\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2581 - accuracy: 0.9244 - val_loss: 0.2531 - val_accuracy: 0.9275\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 16s - loss: 0.1671 - accuracy: 0.9375Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2428 - accuracy: 0.9288 - val_loss: 0.2429 - val_accuracy: 0.9290\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2428 - accuracy: 0.9288 - val_loss: 0.2429 - val_accuracy: 0.9290\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 15s - loss: 0.2544 - accuracy: 0.9375Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2321 - accuracy: 0.9322 - val_loss: 0.2355 - val_accuracy: 0.9305\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2321 - accuracy: 0.9322 - val_loss: 0.2355 - val_accuracy: 0.9305\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.2604 - accuracy: 0.9062Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2243 - accuracy: 0.9342 - val_loss: 0.2298 - val_accuracy: 0.9327\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2243 - accuracy: 0.9342 - val_loss: 0.2298 - val_accuracy: 0.9327\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.1016 - accuracy: 0.9688Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2184 - accuracy: 0.9363 - val_loss: 0.2253 - val_accuracy: 0.9339\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2184 - accuracy: 0.9363 - val_loss: 0.2253 - val_accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 13s - loss: 0.2859 - accuracy: 0.9375Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2138 - accuracy: 0.9372 - val_loss: 0.2224 - val_accuracy: 0.9346\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2138 - accuracy: 0.9372 - val_loss: 0.2224 - val_accuracy: 0.9346\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 15s - loss: 0.1488 - accuracy: 0.9375Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2102 - accuracy: 0.9384 - val_loss: 0.2198 - val_accuracy: 0.9355\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2102 - accuracy: 0.9384 - val_loss: 0.2198 - val_accuracy: 0.9355\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "#RMSprop\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10)\n",
    "Loss.append(history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.4045 - accuracy: 0.0993 - val_loss: 2.3295 - val_accuracy: 0.1031\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.4045 - accuracy: 0.0993 - val_loss: 2.3295 - val_accuracy: 0.1031\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 20s - loss: 2.3579 - accuracy: 0.1250Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.2795 - val_accuracy: 0.1040\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.2795 - val_accuracy: 0.1040\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 2.2633 - accuracy: 0.1250Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2667 - accuracy: 0.1033 - val_loss: 2.2525 - val_accuracy: 0.1103\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2667 - accuracy: 0.1033 - val_loss: 2.2525 - val_accuracy: 0.1103\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 2.2852 - accuracy: 0.0312Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2445 - accuracy: 0.1185 - val_loss: 2.2343 - val_accuracy: 0.1352\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2445 - accuracy: 0.1185 - val_loss: 2.2343 - val_accuracy: 0.1352\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 22s - loss: 2.2844 - accuracy: 0.0000e+00Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2289 - accuracy: 0.1537 - val_loss: 2.2208 - val_accuracy: 0.1818\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2289 - accuracy: 0.1537 - val_loss: 2.2208 - val_accuracy: 0.1818\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 2.2385 - accuracy: 0.0938Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2170 - accuracy: 0.2056 - val_loss: 2.2104 - val_accuracy: 0.2506\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2170 - accuracy: 0.2056 - val_loss: 2.2104 - val_accuracy: 0.2506\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 2.2215 - accuracy: 0.3125Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2079 - accuracy: 0.2873 - val_loss: 2.2022 - val_accuracy: 0.3372\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2079 - accuracy: 0.2873 - val_loss: 2.2022 - val_accuracy: 0.3372\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 2.2150 - accuracy: 0.3438Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2006 - accuracy: 0.3568 - val_loss: 2.1957 - val_accuracy: 0.3981\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2006 - accuracy: 0.3568 - val_loss: 2.1957 - val_accuracy: 0.3981\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 7s - loss: 2.2018 - accuracy: 0.5000Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1949 - accuracy: 0.4045 - val_loss: 2.1906 - val_accuracy: 0.4313\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1949 - accuracy: 0.4045 - val_loss: 2.1906 - val_accuracy: 0.4313\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 2.1824 - accuracy: 0.5625Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1903 - accuracy: 0.4305 - val_loss: 2.1865 - val_accuracy: 0.4486\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1903 - accuracy: 0.4305 - val_loss: 2.1865 - val_accuracy: 0.4486\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "#Adagrad\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adagrad(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10)\n",
    "Loss.append(history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizers</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1916702538728714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.2336618900299072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.21023355424404144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adagrad</td>\n",
       "      <td>2.190291404724121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Optimizers                 Loss\n",
       "0       Adam   0.1916702538728714\n",
       "1        SGD   2.2336618900299072\n",
       "2    RMSprop  0.21023355424404144\n",
       "3    Adagrad    2.190291404724121"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizers</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1916702538728714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.2336618900299072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.21023355424404144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adagrad</td>\n",
       "      <td>2.190291404724121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Optimizers                 Loss\n",
       "0       Adam   0.1916702538728714\n",
       "1        SGD   2.2336618900299072\n",
       "2    RMSprop  0.21023355424404144\n",
       "3    Adagrad    2.190291404724121"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers = [\"Adam\",\"SGD\",\"RMSprop\",\"Adagrad\"]\n",
    "pd.DataFrame(np.array([optimizers,Loss]).T,columns = ['Optimizers','Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.8599 - accuracy: 0.8213 - val_loss: 0.4077 - val_accuracy: 0.9027\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.8599 - accuracy: 0.8213 - val_loss: 0.4077 - val_accuracy: 0.9027\n",
      "Epoch 2/10\n",
      "   1/1875 [..............................] - ETA: 12s - loss: 0.2406 - accuracy: 0.9688Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3470 - accuracy: 0.9100 - val_loss: 0.2995 - val_accuracy: 0.9160\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3470 - accuracy: 0.9100 - val_loss: 0.2995 - val_accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.3574 - accuracy: 0.9062Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2793 - accuracy: 0.9219 - val_loss: 0.2630 - val_accuracy: 0.9265\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2793 - accuracy: 0.9219 - val_loss: 0.2630 - val_accuracy: 0.9265\n",
      "Epoch 4/10\n",
      "   1/1875 [..............................] - ETA: 8s - loss: 0.2541 - accuracy: 0.9375Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2487 - accuracy: 0.9290 - val_loss: 0.2443 - val_accuracy: 0.9313\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2487 - accuracy: 0.9290 - val_loss: 0.2443 - val_accuracy: 0.9313\n",
      "Epoch 5/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.1116 - accuracy: 1.0000Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2300 - accuracy: 0.9343 - val_loss: 0.2314 - val_accuracy: 0.9335\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2300 - accuracy: 0.9343 - val_loss: 0.2314 - val_accuracy: 0.9335\n",
      "Epoch 6/10\n",
      "   1/1875 [..............................] - ETA: 9s - loss: 0.4594 - accuracy: 0.8750Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2174 - accuracy: 0.9375 - val_loss: 0.2227 - val_accuracy: 0.9359\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2174 - accuracy: 0.9375 - val_loss: 0.2227 - val_accuracy: 0.9359\n",
      "Epoch 7/10\n",
      "   1/1875 [..............................] - ETA: 10s - loss: 0.2132 - accuracy: 0.9688Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2081 - accuracy: 0.9402 - val_loss: 0.2166 - val_accuracy: 0.9374\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2081 - accuracy: 0.9402 - val_loss: 0.2166 - val_accuracy: 0.9374\n",
      "Epoch 8/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 0.1324 - accuracy: 0.9688Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2010 - accuracy: 0.9427 - val_loss: 0.2116 - val_accuracy: 0.9383\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2010 - accuracy: 0.9427 - val_loss: 0.2116 - val_accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "   1/1875 [..............................] - ETA: 11s - loss: 0.3233 - accuracy: 0.9375Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1956 - accuracy: 0.9440 - val_loss: 0.2078 - val_accuracy: 0.9399\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1956 - accuracy: 0.9440 - val_loss: 0.2078 - val_accuracy: 0.9399\n",
      "Epoch 10/10\n",
      "   1/1875 [..............................] - ETA: 14s - loss: 0.3446 - accuracy: 0.9062Epoch 10/10\n",
      " 484/1875 [======>.......................] - ETA: 5s - loss: 0.1939 - accuracy: 0.9438"
     ]
    }
   ],
   "source": [
    "#Early Stopping\n",
    "#Build model\n",
    "#SGD\n",
    "fct = 'sigmoid'\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=fct, input_shape=(28*28,)))\n",
    "model.add(layers.Dense(128, activation=fct))\n",
    "model.add(layers.Dense(10, activation=fct))\n",
    "\n",
    "#Make exponential learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "#Define optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(trainX, trainY,validation_data =(testX,testY) ,epochs = 10,callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
